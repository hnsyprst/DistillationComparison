{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.profiler.emit_nvtx at 0x21d6d0577f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "import training_utils as utils\n",
    "import distillation_methods_module\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the training and test sets\n",
    "trans = transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=False, transform=trans, download=True)\n",
    "\n",
    "train_iter = data.DataLoader(mnist_train, batch_size=256, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_iter = data.DataLoader(mnist_test, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher_Net(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_1 = nn.Linear(784, 1200)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.linear_2 = nn.Linear(1200, 1200)\n",
    "\n",
    "        self.linear_3 = nn.Linear(1200, 1200)\n",
    "\n",
    "        self.linear_4 = nn.Linear(1200, 10)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = torch.flatten(input, start_dim=1)\n",
    "        out = self.linear_1(input)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.linear_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.linear_3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.linear_4(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student_Net(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_1 = nn.Linear(784, 600)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.linear_2 = nn.Linear(600, 1200)\n",
    "\n",
    "        self.linear_3 = nn.Linear(1200, 1200)\n",
    "\n",
    "        self.linear_4 = nn.Linear(1200, 10)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = torch.flatten(input, start_dim=1)\n",
    "        out = self.linear_1(input)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.linear_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.linear_3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.linear_4(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t\t  0\n",
      "train_metrics:\t  (0.6287691440582276, 0.76585)\n",
      "test_accuracy:\t  0.8405\n",
      "Epoch:\t\t  1\n",
      "train_metrics:\t  (0.4433426361083984, 0.8390833333333333)\n",
      "test_accuracy:\t  0.8498\n",
      "Epoch:\t\t  2\n",
      "train_metrics:\t  (0.4103693904876709, 0.85055)\n",
      "test_accuracy:\t  0.8612\n",
      "Epoch:\t\t  3\n",
      "train_metrics:\t  (0.3928386678695679, 0.8566833333333334)\n",
      "test_accuracy:\t  0.8645\n",
      "Epoch:\t\t  4\n",
      "train_metrics:\t  (0.37783473879496254, 0.8613166666666666)\n",
      "test_accuracy:\t  0.8663\n",
      "Epoch:\t\t  5\n",
      "train_metrics:\t  (0.37211791191101073, 0.8644666666666667)\n",
      "test_accuracy:\t  0.873\n",
      "Epoch:\t\t  6\n",
      "train_metrics:\t  (0.3635826767603556, 0.8675)\n",
      "test_accuracy:\t  0.8731\n",
      "Epoch:\t\t  7\n",
      "train_metrics:\t  (0.3559310776392619, 0.87075)\n",
      "test_accuracy:\t  0.8762\n",
      "Epoch:\t\t  8\n",
      "train_metrics:\t  (0.3451110579808553, 0.8739833333333333)\n",
      "test_accuracy:\t  0.8738\n",
      "Epoch:\t\t  9\n",
      "train_metrics:\t  (0.33958055356343586, 0.8735666666666667)\n",
      "test_accuracy:\t  0.8833\n"
     ]
    }
   ],
   "source": [
    "teacher = Teacher_Net().to(device)\n",
    "num_epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='none').to(device)\n",
    "optimizer = torch.optim.Adam(teacher.parameters(), lr=0.001)\n",
    "history = utils.train(teacher, train_iter, test_iter, loss_fn, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t\t  0\n",
      "train_metrics:\t  (2.1197416998135546e-05, 0.707)\n",
      "test_accuracy:\t  0.8053\n",
      "Epoch:\t\t  1\n",
      "train_metrics:\t  (9.058115893276408e-06, 0.7954333333333333)\n",
      "test_accuracy:\t  0.8234\n",
      "Epoch:\t\t  2\n",
      "train_metrics:\t  (7.938871916849165e-06, 0.80485)\n",
      "test_accuracy:\t  0.8345\n",
      "Epoch:\t\t  3\n",
      "train_metrics:\t  (7.5720594283969456e-06, 0.8102666666666667)\n",
      "test_accuracy:\t  0.8306\n",
      "Epoch:\t\t  4\n",
      "train_metrics:\t  (6.8598131959637e-06, 0.8157833333333333)\n",
      "test_accuracy:\t  0.8408\n",
      "Epoch:\t\t  5\n",
      "train_metrics:\t  (7.592173454274113e-06, 0.8120166666666667)\n",
      "test_accuracy:\t  0.8325\n",
      "Epoch:\t\t  6\n",
      "train_metrics:\t  (7.211192446993664e-06, 0.8159833333333333)\n",
      "test_accuracy:\t  0.8353\n",
      "Epoch:\t\t  7\n",
      "train_metrics:\t  (7.681641302770004e-06, 0.8112833333333334)\n",
      "test_accuracy:\t  0.834\n",
      "Epoch:\t\t  8\n",
      "train_metrics:\t  (7.671888054270918e-06, 0.81035)\n",
      "test_accuracy:\t  0.8291\n",
      "Epoch:\t\t  9\n",
      "train_metrics:\t  (7.531920372275636e-06, 0.8137)\n",
      "test_accuracy:\t  0.8338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.707,\n",
       "  0.7954333333333333,\n",
       "  0.80485,\n",
       "  0.8102666666666667,\n",
       "  0.8157833333333333,\n",
       "  0.8120166666666667,\n",
       "  0.8159833333333333,\n",
       "  0.8112833333333334,\n",
       "  0.81035,\n",
       "  0.8137],\n",
       " [2.1197416998135546e-05,\n",
       "  9.058115893276408e-06,\n",
       "  7.938871916849165e-06,\n",
       "  7.5720594283969456e-06,\n",
       "  6.8598131959637e-06,\n",
       "  7.592173454274113e-06,\n",
       "  7.211192446993664e-06,\n",
       "  7.681641302770004e-06,\n",
       "  7.671888054270918e-06,\n",
       "  7.531920372275636e-06],\n",
       " [0.8053,\n",
       "  0.8234,\n",
       "  0.8345,\n",
       "  0.8306,\n",
       "  0.8408,\n",
       "  0.8325,\n",
       "  0.8353,\n",
       "  0.834,\n",
       "  0.8291,\n",
       "  0.8338])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student = Student_Net().to(device)\n",
    "optimizer = torch.optim.Adam(student.parameters(), lr=5e-3)\n",
    "\n",
    "d_logits = distillation_methods_module.Logits_Distiller(5, teacher=teacher, student=student, optimizer=optimizer)\n",
    "d_logits.train(train_iter, test_iter, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t\t  0\n",
      "train_metrics:\t  (0.0009428793812791506, 0.00036666666666666667)\n",
      "test_accuracy:\t  0.0001\n",
      "Epoch:\t\t  1\n",
      "train_metrics:\t  (0.00037632959087689717, 0.00028333333333333335)\n",
      "test_accuracy:\t  0.0\n",
      "Epoch:\t\t  2\n",
      "train_metrics:\t  (0.00029673720560967923, 0.00035)\n",
      "test_accuracy:\t  0.0003\n",
      "Epoch:\t\t  3\n",
      "train_metrics:\t  (0.0002591508763531844, 0.00013333333333333334)\n",
      "test_accuracy:\t  0.0004\n",
      "Epoch:\t\t  4\n",
      "train_metrics:\t  (0.00023740152915318808, 0.00015)\n",
      "test_accuracy:\t  0.0005\n",
      "Epoch:\t\t  5\n",
      "train_metrics:\t  (0.00022282475506265958, 0.00015)\n",
      "test_accuracy:\t  0.0007\n",
      "Epoch:\t\t  6\n",
      "train_metrics:\t  (0.00021345531232655048, 0.00011666666666666667)\n",
      "test_accuracy:\t  0.0006\n",
      "Epoch:\t\t  7\n",
      "train_metrics:\t  (0.0002068438465396563, 0.00015)\n",
      "test_accuracy:\t  0.0003\n",
      "Epoch:\t\t  8\n",
      "train_metrics:\t  (0.00019951375455905994, 0.00015)\n",
      "test_accuracy:\t  0.0004\n",
      "Epoch:\t\t  9\n",
      "train_metrics:\t  (0.00019581584818661213, 0.0001)\n",
      "test_accuracy:\t  0.0005\n",
      "Epoch:\t\t  0\n",
      "train_metrics:\t  (0.8968599988301595, 0.72535)\n",
      "test_accuracy:\t  0.8006\n",
      "Epoch:\t\t  1\n",
      "train_metrics:\t  (0.6058464735031128, 0.7666)\n",
      "test_accuracy:\t  0.822\n",
      "Epoch:\t\t  2\n",
      "train_metrics:\t  (0.5563644985198974, 0.78765)\n",
      "test_accuracy:\t  0.8297\n",
      "Epoch:\t\t  3\n",
      "train_metrics:\t  (0.527753889020284, 0.8000666666666667)\n",
      "test_accuracy:\t  0.8536\n",
      "Epoch:\t\t  4\n",
      "train_metrics:\t  (0.49358703931172687, 0.8128666666666666)\n",
      "test_accuracy:\t  0.8542\n",
      "Epoch:\t\t  5\n",
      "train_metrics:\t  (0.4840094000498454, 0.81865)\n",
      "test_accuracy:\t  0.8531\n",
      "Epoch:\t\t  6\n",
      "train_metrics:\t  (0.4721817034403483, 0.8245333333333333)\n",
      "test_accuracy:\t  0.8503\n",
      "Epoch:\t\t  7\n",
      "train_metrics:\t  (0.46327951736450196, 0.8279166666666666)\n",
      "test_accuracy:\t  0.8614\n",
      "Epoch:\t\t  8\n",
      "train_metrics:\t  (0.44466722825368243, 0.83485)\n",
      "test_accuracy:\t  0.8555\n",
      "Epoch:\t\t  9\n",
      "train_metrics:\t  (0.44202712796529137, 0.8354)\n",
      "test_accuracy:\t  0.8598\n"
     ]
    }
   ],
   "source": [
    "student = Student_Net().to(device)\n",
    "optimizer = torch.optim.Adam(student.parameters(), lr=1e-3)\n",
    "\n",
    "d_features = distillation_methods_module.Features_Distiller(hint_layer=teacher.linear_2, guided_layer=student.linear_2, teacher=teacher, student=student, optimizer=optimizer)\n",
    "d_features.train(train_iter, test_iter, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t\t  0\n",
      "train_metrics:\t  (232.40440016276042, 0.09845)\n",
      "test_accuracy:\t  0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(student\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m      4\u001b[0m d_relation \u001b[38;5;241m=\u001b[39m distillation_methods_module\u001b[38;5;241m.\u001b[39mRelations_Distiller(teacher\u001b[38;5;241m=\u001b[39mteacher, student\u001b[38;5;241m=\u001b[39mstudent, optimizer\u001b[38;5;241m=\u001b[39moptimizer)\n\u001b[1;32m----> 5\u001b[0m \u001b[43md_relation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Work\\UNI\\QMUL\\Project\\repo\\DistillationComparison\\distillation_methods_module\\relations_distiller.py:142\u001b[0m, in \u001b[0;36mRelations_Distiller.train\u001b[1;34m(self, train_set, test_set, num_epochs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, train_set, test_set, num_epochs):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_distillation_stage1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstudent, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mteacher, train_set, test_set, num_epochs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_distillation_stage2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstudent, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteacher, train_set, test_set, num_epochs)\n",
      "File \u001b[1;32md:\\Work\\UNI\\QMUL\\Project\\repo\\DistillationComparison\\distillation_methods_module\\relations_distiller.py:81\u001b[0m, in \u001b[0;36mRelations_Distiller.train_distillation_stage1\u001b[1;34m(self, student_net, teacher_net, train_iter, test_iter, num_epochs)\u001b[0m\n\u001b[0;32m     78\u001b[0m history_test_accuracy \u001b[39m=\u001b[39m []\n\u001b[0;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 81\u001b[0m     train_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch_distillation_stage1(student_net, teacher_net, train_iter, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer)\n\u001b[0;32m     82\u001b[0m     test_acc \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mevaluate_accuracy(student_net, test_iter)\n\u001b[0;32m     84\u001b[0m     \u001b[39m# Log the model history\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\UNI\\QMUL\\Project\\repo\\DistillationComparison\\distillation_methods_module\\relations_distiller.py:36\u001b[0m, in \u001b[0;36mRelations_Distiller.train_epoch_distillation_stage1\u001b[1;34m(self, student_net, teacher_net, train_iter, optimizer)\u001b[0m\n\u001b[0;32m     32\u001b[0m metric \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mAccumulator(\u001b[39m3\u001b[39m)\n\u001b[0;32m     34\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 36\u001b[0m \u001b[39mfor\u001b[39;00m features, labels \u001b[39min\u001b[39;00m train_iter:\n\u001b[0;32m     37\u001b[0m     features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     38\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\Work\\UNI\\QMUL\\Project\\repo\\DistillationComparison\\.distenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Work\\UNI\\QMUL\\Project\\repo\\DistillationComparison\\.distenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\UNI\\QMUL\\Project\\repo\\DistillationComparison\\.distenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1315\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m   1314\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[1;32m-> 1315\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1316\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1317\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\Work\\UNI\\QMUL\\Project\\repo\\DistillationComparison\\.distenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1151\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1164\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1165\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[0;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "student = Student_Net().to(device)\n",
    "optimizer = torch.optim.Adam(student.parameters(), lr=1e-3)\n",
    "\n",
    "hint_layers = (teacher.linear_2, teacher.linear_3)\n",
    "guided_layers = (student.linear_2, student.linear_3)\n",
    "\n",
    "d_relation = distillation_methods_module.Relations_Distiller(hint_layers=hint_layers, guided_layers=guided_layers, teacher=teacher, student=student, optimizer=optimizer)\n",
    "d_relation.train(train_iter, test_iter, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.distenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0557164c183bc22d7390206f2e8a2deecaeb7985853eddae99ef9c3a8b0152d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
